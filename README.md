# Internship-Tasks â€“ Developer's Hub Corporation

Welcome to the official repository containing all the tasks completed during my internship at **Developer's Hub Corporation**. This repository documents my learning journey and showcases the practical projects and mini-assignments I worked on, focusing on data analysis, machine learning, and model evaluation.

---

## Overview

During the internship, I gained hands-on experience with:

- Real-world datasets
- Model building and evaluation
- Data visualization and storytelling
- Python libraries for ML and data science

Each task is organized with:
- Code notebooks/scripts
- Visualizations
- Summary reports
- Key learnings

---

## Tasks Included

### Task 1: Data Cleaning and Analysis
- Objective: Clean a raw dataset and extract insights using `pandas` and `seaborn`.
- Tools: pandas, numpy, matplotlib, seaborn

### Task 2: Predict Stock Prices (Short-Term)
- Objective: Predict next-day stock closing prices using Linear Regression and Random Forest.
- Tools: yfinance, scikit-learn, matplotlib

### Task 3: Heart Disease Prediction
- Objective: Predict the likelihood of heart disease using Logistic Regression and Decision Tree.
- Tools: kagglehub, scikit-learn, seaborn, matplotlib

### Task 4: End-to-End ML Pipeline with Scikit-learn
- **Objective**: Build a reusable, production-ready pipeline to predict customer churn using Telco Churn dataset.
- **Key Highlights**:
  - Pipeline API for preprocessing (scaling, encoding)
  - Models: Logistic Regression, Random Forest
  - Hyperparameter tuning with `GridSearchCV`
  - Exported final pipeline using `joblib`
- **Skills Gained**: ML pipeline design, production readiness, reusability

### Task 5: Multimodal ML â€“ Housing Price Prediction
- **Objective**: Predict housing prices using both structured data and images of houses.
- **Key Highlights**:
  - CNNs for image feature extraction
  - Combined image and tabular features
  - Regression model trained on fused data
  - Evaluated using MAE and RMSE
- **Skills Gained**: Multimodal ML, CNNs, data fusion, regression evaluation

### Task 6: Auto Tagging Support Tickets Using LLM
- **Objective**: Automatically classify support tickets into categories using a Large Language Model (LLM).
- **Key Highlights**:
  - Zero-shot and few-shot learning
  - Prompt engineering for category prediction
  - Ranked top 3 tags per ticket
  - Performance comparison: Zero-shot vs Fine-tuned
- **Skills Gained**: LLM usage, text classification, prompt design, multi-label ranking

---

## Skills Applied

- Data Preprocessing and Cleaning  
- Feature Engineering  
- Supervised Machine Learning  
- CNN-based Image Processing  
- LLM-based Text Classification  
- Multimodal Learning  
- Evaluation Metrics (Accuracy, MAE, RMSE, AUC, Confusion Matrix)  
- Grid Search for Hyperparameter Tuning  
- Model Export and Reusability  
- Git & GitHub for Version Control  

---

## ðŸ› Tools & Libraries

- Python  
- pandas, numpy  
- scikit-learn, seaborn, matplotlib  
- yfinance, kagglehub  
- TensorFlow/Keras (for CNNs)  
- joblib  
- OpenAI/LLMs for NLP tasks  

---

## About the Internship

This internship at **Developer's Hub Corporation** focused on enhancing practical knowledge in Data Science and Machine Learning. The tasks emphasized end-to-end pipelinesâ€”from data loading to model evaluation and interpretation.

---

## Contact

For queries or collaborations, feel free to reach out:

**Gul-e-Rana**  
LinkedIn:(https://www.linkedin.com/in/gul-e-rana-02734331a?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app )

---

## License

This repository is open for learning and personal use. Please credit appropriately if you reference this work.

